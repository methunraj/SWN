REACT_APP_API_URL=http://localhost:8000

# Default Model Settings
REACT_APP_DEFAULT_PROVIDER=llamacpp
REACT_APP_DEFAULT_MODEL=qwen/qwen3-4b
# For Ollama, use: REACT_APP_DEFAULT_PROVIDER=ollama
# Common Ollama models: llama2, mistral, codellama, mixtral, neural-chat
# For llama.cpp, the model name should match what's configured in your server

# Model Parameters (Optional)
REACT_APP_DEFAULT_TEMPERATURE=0.7
REACT_APP_DEFAULT_MAX_TOKENS=2048